{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3393057-ea06-4f2d-94c7-9697fccd3a41",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9397067b9282bf77aa677b093849d83d",
     "grade": false,
     "grade_id": "cell-8f51681d0010e7ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "***DISCLAIMER (Read this carefully)***\n",
    "\n",
    "Before you turn this assignment in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel\n",
    "Restart) and then run all cells (in the menubar, select Cell\n",
    "Run All). Do NOT add any cells to the notebook!\n",
    "\n",
    "Do not forget to submit both the notebook AND the files in the data/ subfolder according to the CoC!\n",
    "Make sure you fill in any place that says YOUR CODE HERE or YOUR ANSWER HERE , as well as your name and group below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b4ced-9b69-4c8e-a7d0-12265cc28eea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccbfb02fdc67dc903abb412ab000bf72",
     "grade": false,
     "grade_id": "cell-01518f30645ea1ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 2 (Group)\n",
    "When carrying out a Data-Science project, screening and selecting appropriate data sources for the tasks at hand comes at the beginning. This assignment is about accessing and characterising potential data sources in teams of three. The teams have been randomly assigned. BEWARE! In Assignment 5, you will be asked to provide answers to those questions. Make sure that combining the two datasets makes sense from an analytical perspective!\n",
    "\n",
    "-----\n",
    "## Step 0 (2 points)\n",
    "\n",
    "Find two data sets online (from one or several sources) that would be interesting to combine and create ***data citations*** as Python dictionaries. \n",
    "\n",
    "The data sets should fulfill the following requirements:\n",
    "\n",
    "* Each data set must have a different file format (either CSV, XML, or JSON), please choose\n",
    "  - one CSV file (dataset1) \n",
    "  - and one JSON or XML file (dataset2)\n",
    "\n",
    "* The two datasets should not be two variations of each other (i.e. simply the same dataset for two different regions or timeframes or from the same source just in two different formats)\n",
    "* Workable data-set sizes: The selected or extracted data sets should have thousands of entries (>= 1000), but not more than (<=) 10000 entries. Be \"entries we mean rows or distinguishable key-value pairs). If larger, use an excerpt from the original data set. Justify in detail the extraction criteria in the markdown cell below and \n",
    "  1) add the code used for the extraction in the code cell or describe how you filtered the sample  \n",
    "  2) make the extracted dataset also available at a downloadable URL (for instance in a Github repository, [here](https://raw.githubusercontent.com/AxelPolleres/simple_dataset_sharing_repo/main/test.csv)'s an example)\n",
    "  3) name the new `resourceURL` in the data citation.\n",
    "* You may start from (but you are not limited to) the resource collections hinted at [in the Unit 2 slides](https://datascience.ai.wu.ac.at/ws21/dataprocessing1/unit2.html#slide-53).\n",
    "\n",
    "* Important: The use of datasets from kaggle.com and other curated collections of datasets with accompanying tutorials on processing and analysis (as highlighted to you in Unit 2) is **discouraged**. You are required to use **primary data sources**: This is mainly because we want you to work on data sets that have not been processed with some analysis in mind, so that you show that you can handle (messy) data sets harvested on the brownfields of Data Science. Besides, such curated datasets have been repeatedly used in ready-made case and tutorial work, which makes it basically impossible for us to establish whether your submissions are genuine contributions of yours. There is one viable option: Work backwards from the Kaggle data set to the original data source, obtain updated data from there, and start from there.\n",
    "\n",
    "\n",
    "* Please adhere to the CoC.\n",
    "\n",
    "[Data citations](http://blogs.nature.com/scientificdata/2016/07/14/data-citations-at-scientific-data/) must contain the following details:\n",
    "- creator: provider organisation / author(s) of the data set, e.g. \"Zentralanstalt für Meteorologie und Geodynamik (ZAMG)\"\n",
    "- catalogName: Names of the data repository and/or the Open Data portal used, e.g. Open Data Österreich\"\n",
    "- catalogURL: URL of th repository / portal, e.g. \"https://www.data.gv.at/\"\n",
    "- datasetID: (specific to the data repository), e.g. \"https://www.data.gv.at/katalog/dataset/zamg_meteorologischemessdatenderzamg\"\n",
    "- resourceURL: a URL where the CSV, XML or JSON file can be downloaded, e.g. \"https://www.football-data.co.uk/new/JPN.csv\"\n",
    "- pubYear: Dataset publication year, i.e. since when it is published, e.g. \"2012\"\n",
    "- lastAccessed: when have you last accessed the dataset (i.e. datetime of accessing, obtaining a copy of the data set) in ISO Format? e.g. \"2021-03-08T13:55:00\"\n",
    "\n",
    "One final note: as mentioned above, if you want to use a repository for your file download (e.g. github), you are allowed to do that. The most important part is that the URL can be accessed stably for each dataset you have chosen. \n",
    "\n",
    "Store the data citation in a dictionary for each of the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94ac2b05-1102-4cf7-96a3-f1ec47459ece",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b6ee8b15f725340d21f67892d57f1cf",
     "grade": true,
     "grade_id": "cell-cea2669d70d8d76a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "dataset1= {\n",
    "    \"creator\" : \"U.S. Department of Tresury\" ,\n",
    "    \"catalogName\" : \"U.S. Department of Tresury Data\" ,\n",
    "    \"catalogURL\" : \"https://home.treasury.gov/\" ,\n",
    "    \"datasetID\" : \"https://home.treasury.gov/resource-center/data-chart-center/interest-rates/TextView?type=daily_treasury_yield_curve&field_tdr_date_value_month=202404\" ,\n",
    "    \"resourceURL\" : \"https://raw.githubusercontent.com/davide-229/WU-DA1/main/YieldCurveUSA.xml\"  ,\n",
    "    \"pubYear\" :  \"2024\"  ,\n",
    "    \"lastAccessed\" : \"2024-08-04T21:10:10\"  ,\n",
    "}\n",
    "\n",
    "dataset2= {\n",
    "    \"creator\" : \"Yahoo Finance\" ,\n",
    "    \"catalogName\" : \"Yahoo Fiance/^NDX\" ,\n",
    "    \"catalogURL\" : \"https://finance.yahoo.com/\" ,\n",
    "    \"datasetID\" : \"https://finance.yahoo.com/quote/%5ENDX\" ,\n",
    "    \"resourceURL\" : \"https://raw.githubusercontent.com/davide-229/WU-DA1/main/%5ENDX.csv\"  ,\n",
    "    \"pubYear\" : \"2024\"  ,\n",
    "    \"lastAccessed\" : \"2024-08-04T22:59:00\"  ,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852966b3-7ce6-47e0-a879-2de74b756861",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39009fd5ac6f4d6b559120b873b92451",
     "grade": true,
     "grade_id": "cell-d3cc293b6207d1c7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal, assert_in, assert_true\n",
    "import traceback\n",
    "import sys\n",
    "import os\n",
    "\n",
    "assert_equal(type(dataset1), dict)\n",
    "assert_equal(type(dataset2), dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c1bfa-decc-4711-83c1-87c761bda55e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8bd1475fa3535b9a58bf34f0a20219c7",
     "grade": false,
     "grade_id": "cell-a34ab569805a650e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the following structure for your answer below:\n",
    "\n",
    "Data set 1\n",
    "\n",
    "(Describe the source and the general content of the dataset and why you chose it)\n",
    "\n",
    "Data set 2\n",
    "\n",
    "(Describe the source and the general content of the dataset and why you chose it)\n",
    "\n",
    "Project ideas\n",
    "\n",
    "(Describe in your own words, which kind of tasks could be addressed by combining the selected data sets, esp. how the two data sets fit together and what complementary information they contain; Formulate a question that could be potentially answered by combining data from both datasets; how could the data sets be combined exactly? 250 words max. BEWARE! In Assignment 5, you will be asked to provide answers to those questions. Make sure that combining the two datasets makes sense from an analytical perspective!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b04cd31-a41c-4d42-b756-87567ed08ee8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25e589c21292c28ecbe9193e15daa7b9",
     "grade": true,
     "grade_id": "cell-9bc09f21e0c42050",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Data set 1\n",
    "\n",
    "The first dataset is an XML file containing the data of the interest rate curve yield curve of the United States. The values refer to a period from 2013 to 2023 and are provided on a daily basis. The source of the data is the official website of the U.S. Department of Treasury. The data was retrieved from the website following the instructions at this link: https://home.treasury.gov/treasury-daily-interest-rate-xml-feed. We created a loop to retrieve the data year-by-year and we uploaded it to a git hub repository so that it can be easily accessible at once.\n",
    "\n",
    "The data provided correspond to the daily interest rate on U.S. Treasury bonds for at least 12 time periods that range from 1 month to 30 years daily.. It is interesting to notice that the 2 moth and 4-month treasury bonds were introduced during the analyze period and for this reason, we do not have values for the first part.\n",
    "\n",
    "The reason behind our choice to consider this data and the relative time period are strictly related to our research question that will be presented in the “Project idea” paragraph.\n",
    "\n",
    "Code used to retrieve the data yearly in the selected period:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "all_data = \"\" for i in range(2023,2024): url = \"https://home.treasury.gov/resource-center/data-chart-center/interest-rates/pages/xml?data=daily_treasury_yield_curve&field_tdr_date_value=\" + str(i)\n",
    "\n",
    "with urllib.request.urlopen(url) as f:\n",
    "    year_data = f.read().decode(\"utf-8\")\n",
    "    if i > 2013 : year_data = year_data[665:]\n",
    "    if i < 2023 : year_data = year_data[:len(year_data)-7]\n",
    "    \n",
    "    all_data += year_data\n",
    "\"\"\"\n",
    "\n",
    "Data set 2\n",
    "\n",
    "In the second dataset, we are provided with the historical performance in the Nasdaq 100 in CSV format. The Nasdaq 100 (NDX) is one of the main U.S. stock indexes containing the biggest 100 non-financial companies of the Nasdaq Stock Exchange. The index is a weighted index where the weight of each company is based on its market capitalization (some rules apply to the biggest companies). The data was retrieved from Yahoo Finance where it is possible to access and download historical financial data from a defined period. The file was then uploaded to a git hub repository The dataset is based on the same period as the first one (2013-2023) and it provides information on the daily market performance and the volume of the index (with the clear exception of the closing days of the stock market). We are provided with: “Open”, “High”, “Low”, “Close”, “Adjusting Closing” and “Volume”, these represent the respective prices at which trading begins, reaches its highest point, reaches its lowest point, and concludes for a given trading day, with “Adjusting Closing” considering for dividends and stock splits and “Volume” measures the level of activity. As normal practice in the financial industry when considering indexes the numbers are given in the price-weighted index.\n",
    "\n",
    "Project ideas\n",
    "\n",
    "The two datasets can be easily joined by the data attribute. In such a situation, we will be provided with a snapshot of the financial performance in the U.S: financial markets (both bonds and stock market) in the decades ranging from 2013 to 2023.\n",
    "\n",
    "Our idea was to investigate the correlation between interest rates and stock market performance. In looking for a specific stock index to consider we selected the Nasdaq first because it represents one major U.S. stock index but also because financial companies are not included, in which the correlation with interest might be more obvious. Our choice to consider the decade from 2013 to 2023 is given by the fact that the last 10 years provide already very different situations in terms of interest rates. We stopped in 2023 to have the last complete time period.\n",
    "\n",
    "The questions that we want to try to answer in our project are:\n",
    "\n",
    "What was the development of the U.S. yield curve in the last 10 years?\n",
    "How did the NDX perform in the last 10 years?\n",
    "Is there any correlation between the index performance and the interest rate?\n",
    "Are we presented with different levels of volatility in the index with different interest rate levels?\n",
    "What is the market reaction (from the index) to a change in interest rate?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a43ce55-9c0b-44b2-a833-8e4e107175da",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed8978a8e226a4b0c92d461641d71447",
     "grade": false,
     "grade_id": "cell-426859b26b9c84e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "------\n",
    "## Step 1 - File Access (3 points)\n",
    "\n",
    "Write a Python function `accessData` that takes the dataset dictionary created in step 0 as an input and returns an extended dictionary including following additions:\n",
    "\n",
    "* Write code that accesses the dataset from its `resourceURL` using the python `requests` package:\n",
    " * detects whether it's and XML, CSV or JSON file by\n",
    "     * checking whether the download URL **ends** with suffix \"xml\", \"json\", \"csv\" \n",
    "     * checking whether the \"Content-Type\" HTTP header field contains information about the format, hinting on XML, JSON or CSV, i.e., check whether the substring XML, JSON or CSV appears in the \"Content-Type\" header in either upper- or lowercase. \n",
    " * Detects the file size from the HTTP header (converted to KB) of each data set, clearly documenting your actions (e.g. through commented code).\n",
    "\n",
    "The result of the code below should extend your dictionaries `dataset1` and `dataset2` with two keys named \n",
    "* `\"detectedFormat\"` (which has one of the following values: `\"XML\"`, `\"JSON\"`, `\"CSV\"`, or `\"unknown\"`, if nothing could be detected from checking the suffix or HTTP header, or if the information in both was inconsistent)\n",
    "* and `\"filesizeKB\"` which contains the filesize in KB (Conversion should be done accordingly to decimal SI prefixes) from the number of bytes in the header-information. If there is no respective header information return 0.\n",
    "* If the detected format is `\"unknown\"`, the expected filesize to be returned is also 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a06da511-204d-4316-bc92-507835acbe27",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ce47a1d2b5782eb291c725baea5db29",
     "grade": false,
     "grade_id": "cell-87173edcb1445261",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE \n",
    "import requests\n",
    "\n",
    "def accessData(datadict):\n",
    "    # YOUR CODE HERE\n",
    "    #First part of the function \n",
    "\n",
    "    #Check type method 1\n",
    "\n",
    "    end = datadict[\"resourceURL\"][len(datadict[\"resourceURL\"])-4:]\n",
    "\n",
    "\n",
    "    if end[len(end)-3:]== \"xml\" : type1 = \"XML\"\n",
    "    elif end[len(end)-3:] == \"csv\": type1 = \"CSV\"\n",
    "    elif end == \"json\": type1 = \"JSON\"\n",
    "    else: type1 = \"unknown\"\n",
    "\n",
    "    \n",
    "    #Cheking method 2\n",
    "    try:\n",
    "        with requests.head(datadict[\"resourceURL\"]) as response: \n",
    "            content = response.headers[\"Content-Type\"]\n",
    "        \n",
    "\n",
    "        if \"xml\" in content or \"XML\" in content: type2 = \"XML\"\n",
    "        elif \"csv\" in content or \"CSV\" in content: type2 = \"CSV\"\n",
    "        elif \"json\" in content or \"JSON\" in content: type2 = \"JSON\"\n",
    "        else:type2 = \"unknown\"\n",
    "    \n",
    "    except (KeyError):\n",
    "            type2 = \"unknown\"\n",
    "\n",
    "    #Check the 2 resulsts, if equal if one unknown if different types \n",
    "    if type1 == type2: type0 = type1\n",
    "    elif type1 == \"unknown\": type0 = type2\n",
    "    elif type2 == \"unknown\": type0 = type1\n",
    "    else: type0 = \"unknown\"\n",
    "    \n",
    "    #Second part of the function \n",
    "    if type0 == \"unknown\" : sizeKB = 0\n",
    "    else:\n",
    "        try:\n",
    "            length = response.headers['content-length']\n",
    "            length = int(length)\n",
    "    \n",
    "        except (ValueError, TypeError, KeyError):\n",
    "    \n",
    "            length = None\n",
    "\n",
    "        if length is None: sizeKB = 0\n",
    "        else:sizeKB = length / 1000\n",
    "    \n",
    "    #Adding the inforamtion to the dictionary\n",
    "    \n",
    "    datadict[\"detectedFormat\"] =  type0\n",
    "    datadict[\"filesizeKB\"] = sizeKB\n",
    "    \n",
    "\n",
    "    return datadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba078d8-b700-4cb8-8a18-4a2fa86dc210",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d95fb7a29ffb9cea68ca365e17633265",
     "grade": true,
     "grade_id": "cell-09b529ecf9606ac6",
     "locked": true,
     "points": 0.24,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Basic tests to see if your solution meets the foundational demands described in the task description\n",
    "from nose.tools import assert_equal, assert_in, assert_true\n",
    "dataset1= accessData(dataset1)\n",
    "dataset2= accessData(dataset2)\n",
    "assert_in(dataset1[\"detectedFormat\"], [\"XML\", \"JSON\", \"CSV\", \"unknown\"])\n",
    "assert_in(dataset2[\"detectedFormat\"], [\"XML\", \"JSON\", \"CSV\", \"unknown\"])\n",
    "assert_true(isinstance(dataset1[\"filesizeKB\"], (int, float)))\n",
    "assert_true(isinstance(dataset2[\"filesizeKB\"], (int, float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81c70a0c-34d4-47db-952b-46d4cb3bf347",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "580596224539603a63b4a559ba37d01f",
     "grade": true,
     "grade_id": "cell-b1ef1760abd62f3f",
     "locked": true,
     "points": 0.22,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2fa6983-d7c6-431a-89a9-c86ac7a0451d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c795cbd00b10bbb32830e3026ed4f676",
     "grade": true,
     "grade_id": "cell-b16c0da0f2b8dc22",
     "locked": true,
     "points": 0.22,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74bd86f0-1a8d-4270-9b79-ad4ad967266b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfc68663db636e99afeb58486c87a1aa",
     "grade": true,
     "grade_id": "cell-e19b418cde2ba027",
     "locked": true,
     "points": 0.22,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d6fbc1-2eea-4017-acbc-4cd735cccab5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e6d3529936b739da626bdd9098061ca",
     "grade": true,
     "grade_id": "cell-278bfc1d2c26772d",
     "locked": true,
     "points": 0.22,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64df8a63-b6c3-4d4a-83a8-e4e79f9cd122",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3537723c82c9905d481fbe710834686a",
     "grade": true,
     "grade_id": "cell-1fb00904a60db5c7",
     "locked": true,
     "points": 0.22,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac351364-b28e-4cde-9423-8aa4f9b437bf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5c98a2910050eb9f43a5d55f44ef1dc",
     "grade": true,
     "grade_id": "cell-affc2fa2a6b001c9",
     "locked": true,
     "points": 0.22,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "859d99e8-bbb2-4729-937d-0c7ada7e4047",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16708dc91e800626b08b2e3703170884",
     "grade": true,
     "grade_id": "cell-00e4aadd3923d75d",
     "locked": true,
     "points": 0.22,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad6b1413-ccd8-4c90-aa55-cc0910f880e5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d776ae85271b5fedf7a8a24b2154506",
     "grade": true,
     "grade_id": "cell-d0566ccfef366cdd",
     "locked": true,
     "points": 0.22,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa69593-670f-4b2c-b5d0-1c70c9970b92",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98e00d798908db7a765a41c1c61b7548",
     "grade": false,
     "grade_id": "cell-dcd3aa38b0b6d216",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Please explain your findings, using the following structure for your answer below (in \"other remarks\" you can explain, for instance, why you think your code did not detect the correct format, if needed)\n",
    "\n",
    "Data set 1\n",
    "\n",
    "(format, size, other remarks)\n",
    "\n",
    "Data set 2\n",
    "\n",
    "(format, size, other remarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ffd91-c334-43fd-aa68-ae9aeb9ae24b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56e8a3407f0b2570544c4791d8468d5f",
     "grade": true,
     "grade_id": "cell-40248ad63aa2baea",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Data set 1\n",
    "\n",
    "The function managed to correctly detect the format of the 2 files. However, if we analyze the function more deeply we can see that “type2” we can see that in both occasions the result is “unknown”. In fact the output of this part of the code:\n",
    "\n",
    "“””\n",
    "\n",
    "    with requests.head(datadict[\"resourceURL\"]) as response: \n",
    "        content = response.headers[\"Content-Type\"]\n",
    "print(content)\n",
    "\n",
    "“””\n",
    "\n",
    "Is in both cases “text/plain”. We believe that this problem is given by the way git hub recognizes the 2 uploaded files, even though are uploaded with the correct extensions “CSV” and “XML”, they are recognized as text. This is confirmed by the fact that with other test datasets directly accessed, at least in our cases, also type2 was correctly detected.\n",
    "\n",
    "We could investigate more why git hub does not correctly recognize the file format but, fortunately, from the way the task is structured, it is enough that one of the 2 methods correctly identifies the file type and that the 2 information are not inconsistent.\n",
    "\n",
    "We also noticed that, especially in some cases, the file size seems to be slightly lower than the real size in kB when the file is downloaded, but after a quick research we understood that there are several reasons why this could be the case (compression, encoding, network…) so also in this case we gladly do not go into much details.\n",
    "\n",
    "Data set 2\n",
    "\n",
    "Same comments as in in data set2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f26a4ed-ce75-4a64-8c94-0eff3cb8de7a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8ba2987efce440ec7e6f4d4857bd88e",
     "grade": false,
     "grade_id": "cell-c236c8ec72c4dded",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "-----\n",
    "## Step 2  (5 points) - Format Validation\n",
    "\n",
    "Establish that the two data files obtained are well-formed according to the detected data format (CSV, JSON, or XML). That is, the syntax used is valid according to accepted syntax definitions. Are there any violations of well-formedness?\n",
    "\n",
    "\n",
    "Proceed as follows (for each data file, in turn): according to the \"suspected\" data format from Step 1:\n",
    "\n",
    "  1. Use an _online validator_ for CSV, XML, and JSON, respectively, to confirm whether the files you downloaded in Step 1 are well-formed for the respective file format, document your findings and modify the file as described: \n",
    "\n",
    "   a. **Case 1**: no well-formedness errors were detected: \n",
    "    * Generally describe at least 3 well-formedness checks that your data sets, depending on its \"suspected\" format (against the background knowledge of Unit 2) should fulfill;\n",
    "    * Store a local copy of the file called `data_notebook-[notebook-nr.]_[name].[file extension]` in the `data/` subfolder\n",
    "    * Create another local copy of your data file called `data_notebook-[notebook-nr.]_[name]-invalid.[file extension]` and introduce a selected well-formedness violation (one occurrence) therein;\n",
    "    * document that the online validator you used finds the error you introduced\n",
    "\n",
    "   b. **Case 2**: well-formedness errors occurred:\n",
    "    * Document the occurrences by printing out the error message and describe the types of well-formedness violation that were reported to you.\n",
    "    * Store a local copy called `data_notebook-[notebook-nr.]_[name]-invalid.[file extension]`  in the `data/ subfolder`\n",
    "    * Create another local copy called `data_notebook-[notebook-nr.]_[name].[file extension]`, of your data file that fixes the well-formedness violations therein manually.  \n",
    "    \n",
    "**Please note that the datasets in the `data/` subfolder are for documentation only. Do not access those for subsequent steps!**\n",
    "    \n",
    "\n",
    "  2. Write a Python function `parseFile(datadict, format)` that that accesses the dataset from its `resourceURL`. The dataset should then be checked accordingly the given parser for the parameter `format` to check the following:\n",
    "     * CSV: Returns `True`, if a consistent delimiter out of `\",\",\";\",\"\\t\"` can be detected, such that each row has the same (> 1) number of elements, otherwise False\n",
    "     * JSON: Returns `True` if the file can be parsed with the `json` package, catching any parsing exceptions.\n",
    "     * XML: Returns `True` if the file can be parsed with the `xmltodict` package, catching any parsing exceptions.\n",
    "     * Returns `False` if any other format is supplied by the parameter.\n",
    "     \n",
    "In order to handle parsing exceptions and errors from the used packages, you can use [catching exceptions](https://docs.python.org/3/tutorial/errors.html), such that the program does not simply fail to check whether the file is parseable as the format specified in `format`    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d77f70-6543-4aab-9306-010a706fd09b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d5a2e097de799a7b80df50520dad2457",
     "grade": false,
     "grade_id": "cell-57dc295d9edd354d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the following structure for your answer in the cell below to document **Step 2.1**:\n",
    "\n",
    "***Data set 1***\n",
    "\n",
    "*(validator used, validation results, describe the modification to fix the file or to create an invalid version of it)*\n",
    "\n",
    "***Data set 2***\n",
    "\n",
    "*(validator used, validation results, describe the modification to fix the file or to create an invalid version of it)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec87d67-75e8-4bc7-9502-f24598959a5e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b03b52aa01bb4c3dd985217938fc69c4",
     "grade": true,
     "grade_id": "cell-7326ff597819ce15",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Data set 1\n",
    "\n",
    "Starting from data set 1, we used an online validator to check the correctness of the XML format (our suspected file format from task 1), we used the online validator at the following link:\n",
    "\n",
    "https://jsonformatter.org/xml-validator\n",
    "\n",
    "Output: “Valid XML”\n",
    "\n",
    "no well-formedness errors were found.\n",
    "\n",
    "\n",
    "3 well-formedness checks xml:\n",
    "\n",
    "• For an XML document to be properly formed, it's essential that every opening tag has a corresponding closing tag.\n",
    "\n",
    "•Elements must be nested correctly within each other. For example, Name is an example of correct nesting, while Name is incorrect.\n",
    "\n",
    "• Also, within a single element, each attribute must have a unique value. Correct usage would be XML Basics, but XML Basics is not valid.\n",
    "\n",
    "\n",
    "After not having found any error we manually introduced one small error in both files.\n",
    "\n",
    "For data set 1 (the XML file), we removed the first “<\\entries> ( the first entry closing), we then re-used the same online validator:\n",
    "\n",
    "Output:\n",
    "\n",
    "“Invalid XML: This page contains the following errors: error on line 77740 at column 8: Opening and ending tag mismatch: entry line 10 and feed”\n",
    "\n",
    "\n",
    "\n",
    "Data set 2\n",
    "\n",
    "We then repeated the process with data set 2, our suspected CSV file. We used the validator at the following link:\n",
    "\n",
    "https://toolkitbay.com/tkb/tool/csv-validator\n",
    "\n",
    "Output: “File is Valid”\n",
    "\n",
    "Also in this case no well-formedness errors were found.\n",
    "\n",
    "3 well-formedness checks csv:\n",
    "\n",
    "• In the header and in every record, fields can appear, which are divided by commas and there might be one or more of these fields.\n",
    "\n",
    "• The file should maintain a consistent number of fields in every line.\n",
    "\n",
    "• Fields can be optionally enclosed within double quotation marks.\n",
    "\n",
    "After not having found any error we manually introduced one small error in both files.\n",
    "\n",
    "Moving to data set 2 (CSV file) we substitute the first “,” (the delimiter) with “;” in the second line (first row) changing the consistency of the file. We then checked the file in the online validator.\n",
    "\n",
    "Output:\n",
    "\n",
    "“Record #1 has error: wrong number of fields”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b5bfb28-0a4f-4fbe-a2ed-4d8e9c3d52d8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eed04eccfe7b9897bc09aa0b00b66d27",
     "grade": false,
     "grade_id": "cell-e72d44bc996d8aaf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import json\n",
    "import xmltodict\n",
    "\n",
    "def parseFile(datadict, format):\n",
    "    # YOUR CODE FOR STEP 2.2 HERE\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # Trying to fetch the dataset from its URL\n",
    "    resourceURL = datadict.get('resourceURL')\n",
    "    if not resourceURL:\n",
    "        return False  # No URL found\n",
    "    \n",
    "    try:\n",
    "        resp = requests.get(resourceURL)\n",
    "        resp.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching the dataset: {e}\")\n",
    "        return False\n",
    "\n",
    "    if format == 'CSV':\n",
    "        return validate_csv(resp.text)\n",
    "    elif format == 'JSON':\n",
    "        return validate_json(resp.text)\n",
    "    elif format == 'XML':\n",
    "        return validate_xml(resp.text)\n",
    "    else:\n",
    "        return False\n",
    "     \n",
    "# Helper functions to validate the format of the file   \n",
    "# CSV validation\n",
    "def validate_csv(resp):\n",
    "    for delimiter in [',', ';', '\\t']:\n",
    "        reader = csv.reader(resp.splitlines(), delimiter=delimiter)\n",
    "        try:\n",
    "            rows = list(reader)\n",
    "        except csv.Error:\n",
    "            continue  # Try the next delimiter\n",
    "        if rows and all(len(row) == len(rows[0]) and len(row) > 1 for row in rows):\n",
    "            return True # Found a consistent delimiter\n",
    "    return False\n",
    "#Json validation\n",
    "def validate_json(resp):\n",
    "    try:\n",
    "        json.loads(resp)\n",
    "        return True\n",
    "    except json.JSONDecodeError:\n",
    "        return False\n",
    "#XML validation\n",
    "def validate_xml(resp):\n",
    "    try:\n",
    "        xmltodict.parse(resp)\n",
    "        return True\n",
    "    except xmltodict.expat.ExpatError:\n",
    "        return False\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dce5b307-c87b-4906-afc6-9c1febd645e7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8dba04d64b7a6dd6cedc9434b6ec78d7",
     "grade": true,
     "grade_id": "cell-44a0730c406d4f1f",
     "locked": true,
     "points": 0.375,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal, assert_in, assert_true\n",
    "assert_equal([parseFile(dataset1, \"XML\"),\n",
    "    parseFile(dataset1, \"JSON\"),\n",
    "    parseFile(dataset1, \"CSV\"),\n",
    "    parseFile(dataset2, \"XML\"),\n",
    "    parseFile(dataset2, \"JSON\"),\n",
    "    parseFile(dataset2, \"CSV\")].count(True), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19e2c763-6dcd-4ab4-9cf1-07d376bbf933",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b1707e0eafd11b04790a361420d22f8",
     "grade": true,
     "grade_id": "cell-a6fe57057ce3e18e",
     "locked": true,
     "points": 0.375,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7089c06-e16f-4372-8a41-7ac26ed76f45",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d7ea4929d3fa5b005a9913921d9a2a8",
     "grade": true,
     "grade_id": "cell-aa7fd9b40f36f086",
     "locked": true,
     "points": 0.375,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f1b12f1-52e3-4ffc-9cb8-a8ed3f635891",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82e57ee635b1b3b871c3ef9f1f3cc9b1",
     "grade": true,
     "grade_id": "cell-7d845903b5b4589e",
     "locked": true,
     "points": 0.375,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ca9bedd-01f2-41c5-aad8-04e5701fae0c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fb76deee21dbae2ae9299edf7443ba9",
     "grade": true,
     "grade_id": "cell-d647097f451b66c2",
     "locked": true,
     "points": 0.375,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27211989-c7bb-42e8-8d3b-cd5286758d7a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8022febe031b0a602b2a33443b001bbc",
     "grade": true,
     "grade_id": "cell-f77b7d77dfebf6fc",
     "locked": true,
     "points": 0.375,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68c822dd-fa67-436d-9f2c-3652682ffbd7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8007b3d48186c30912d246c3bc6023a3",
     "grade": true,
     "grade_id": "cell-f7ec87ba2b1d4805",
     "locked": true,
     "points": 0.375,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "069798e6-e2f8-4c44-96d4-7cbf1f189275",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd605035aa02f06cfd9bb967aca1fa38",
     "grade": true,
     "grade_id": "cell-0872aa870b41a0f9",
     "locked": true,
     "points": 0.375,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14967cf4-e8da-4e9a-90a9-752f1f441915",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "121f1b6432df1a273435a4617379de23",
     "grade": false,
     "grade_id": "cell-c0772a5952f0b1fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "-----\n",
    "## Step 3 - Content analysis (5 points)\n",
    "\n",
    "Similar to the Python function `parseFile(datadict,format)` above, now create a new Python function `describeFile(datadict)` that analyses the given file according to the respective format detected in Step 1 and returns a dictionary containing the following information:\n",
    "\n",
    "* for CSV files: number of columns, number of rows, column number (from 0 to n) of the column which contains the longest text. You do not have to try to transform any string to integer or float, simply take the values as is from the csv file. That is, the resulting dictionary should have the following form:\n",
    "\n",
    "    ```\n",
    "    { \"numberOfColumns:\"  ...,\n",
    "       \"numberOfRows\":  ... ,\n",
    "       \"longestColumn\" : ... }\n",
    "    ```\n",
    "\n",
    "* for JSON files: number of different attribute names, nesting depth, length of the longest list appearing in an attribute value. That is, the resulting dictionary should have the following form:\n",
    "\n",
    "    ```\n",
    "    { \"numberOfAttributes:\" ... ,\n",
    "      \"nestingDepth\":  ... ,\n",
    "      \"longestListLength\" : ... }\n",
    "     ```\n",
    "\n",
    "  Here the `longestListLength` should be set to 0 if no list appears. [Nesting depth](https://www.tutorialspoint.com/find-depth-of-a-dictionary-in-python) is defined as follows: \n",
    "   * a flat JSON object with only atomic attribute values has depth 1. \n",
    "   * a JSON attribute with another object as value (or another oject as member of a list value!) increases the depth by 1\n",
    "   * and so on.\n",
    "\n",
    "\n",
    "* for XML files: number of different element and attribute a names (i.e. the sum of both), nesting depth, maximum numeric value in the dataset. That is, the resulting dictionary should have the following form:\n",
    "\n",
    "    ```\n",
    "    { \"numberOfElementsAttributes:\" ... ,\n",
    "      \"nestingDepth\":  ... ,\n",
    "      \"maxNumericValue\" : ... }\n",
    "     ```\n",
    "\n",
    "  Here the `maxNumericValue` should be set to 0 if there are no numberic values present. Nesting depth is defined as the nesting depth of elements.\n",
    "  \n",
    "For files that cannot be parsed with respective given format, the function should simply return an empty dictionary (`{}`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4494b82-73ef-410f-8646-ce960e85fae7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e05f4df55ec10447c9c1c3dbc5e19dc",
     "grade": false,
     "grade_id": "cell-223d8521820ec726",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "def describeFile(datadict):\n",
    "\n",
    "    #Output dictionary as global variable \n",
    "    global diz\n",
    "    \n",
    "    diz = {}\n",
    "    \n",
    "    #Take the info we need for the dictionary \n",
    "    format = datadict[\"detectedFormat\"]\n",
    "    resourceURL = datadict[\"resourceURL\"]\n",
    "\n",
    "    #Bse on the format run the corresponding function\n",
    "\n",
    "    if not resourceURL:\n",
    "        return (\"No resourceURL\") # No URL found\n",
    "\n",
    "    try:\n",
    "        resp = requests.get(resourceURL)\n",
    "        resp.raise_for_status()\n",
    "    except requests.exceptions.RequestException:\n",
    "        return {}\n",
    "\n",
    "    if format == 'CSV':\n",
    "        return csv_analysis(resp,datadict)\n",
    "    elif format == 'JSON':\n",
    "        return json_analysis(resp,datadict)\n",
    "    elif format == 'XML':\n",
    "        return xml_analysis(resp, datadict)\n",
    "\n",
    "\n",
    "#CSV function\n",
    "def csv_analysis(resp_csv, datadict):\n",
    "    \n",
    "    #Parse the file\n",
    "    try:\n",
    "        dialect = csv.Sniffer().sniff(resp_csv.content[:5000].decode(\"utf-8\"))\n",
    "        delimiter = dialect.delimiter\n",
    "\n",
    "        reader = csv.reader(resp_csv.text.splitlines(), delimiter=delimiter)\n",
    "\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "    #Initialize variables and loop\n",
    "    n_columns = 0\n",
    "    n_rows  = 0\n",
    "    \n",
    "    #List with all entries\n",
    "    all_entries = []\n",
    "    for row in reader:\n",
    "        n_rows += 1\n",
    "        if len(row) > n_columns:\n",
    "            n_columns = len(row)\n",
    "\n",
    "        for element in row:\n",
    "            all_entries.append(element)\n",
    "\n",
    "\n",
    "    for i, value in enumerate(all_entries):\n",
    "        if type(value) == str:\n",
    "            all_entries[i] = len(value)\n",
    "        else:\n",
    "            all_entries[i] = 0\n",
    "\n",
    "    #Index longest in our list\n",
    "    list_ind_longest = all_entries.index(max(all_entries))\n",
    "    #Transform the index in the list into colunm index based on column length\n",
    "    column_index_longest = n_columns if (list_ind_longest % n_columns) == 0 else (list_ind_longest % n_columns) - 1\n",
    "\n",
    "    diz[\"numberOfColumns\"] = n_columns\n",
    "    diz[\"numberOfRows\"] = n_rows\n",
    "    diz[\"longestColumn\"] = column_index_longest\n",
    "\n",
    "    return diz\n",
    "\n",
    "#JSON\n",
    "\n",
    "def json_analysis(resp_json,datadict):\n",
    "    \n",
    "    #Parse the file (data_dict is a dictiory)\n",
    "    try:\n",
    "        data_dict = resp_json.json()\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "    #Initialize the variables\n",
    "    max_level = 0\n",
    "    current_level = 0\n",
    "    keys = []\n",
    "    max_ll = 0\n",
    "\n",
    "    #create two recursive fuction to handle the nested object and keep track of the variables we wanted\n",
    "    \n",
    "    #Function to handle dictiories\n",
    "    def dic(d, level):\n",
    "        nonlocal  max_level, current_level, keys\n",
    "        current_level = level\n",
    "        if current_level > max_level:\n",
    "            max_level = current_level\n",
    "\n",
    "        for k in d.keys():\n",
    "            keys.append(k)\n",
    "            if isinstance(d[k], dict):\n",
    "                dic(d[k], level + 1)\n",
    "            elif isinstance(d[k], list):\n",
    "                lista(d[k], level)\n",
    "\n",
    "    #Function to handle lists\n",
    "    def lista(x, level):\n",
    "        nonlocal  max_level, max_ll\n",
    "        current_ll = len(x)\n",
    "        if current_ll > max_ll: max_ll = current_ll\n",
    "\n",
    "        for el in x:\n",
    "            if isinstance(el, list):\n",
    "                lista(el, level)\n",
    "            elif isinstance(el, dict):\n",
    "                dic(el, level + 1)\n",
    "\n",
    "    #Evaluate the function\n",
    "    dic(data_dict,1)\n",
    "    \n",
    "    #Number of diffrent keys\n",
    "    n_att = len(list(set(keys)))\n",
    "\n",
    "\n",
    "    diz[\"numberOfAttributes:\"] = n_att\n",
    "    diz[\"nestingDepth:\"] = max_level\n",
    "    diz[\"longestListLength\"] = max_ll\n",
    "    \n",
    "    return diz\n",
    "\n",
    "\n",
    "#XML\n",
    "def xml_analysis(resp_xml, datadict):\n",
    "\n",
    "    #Parse the file\n",
    "    try:\n",
    "        data_dict = xmltodict.parse(resp_xml.text)\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "    #Initialize the variables and loop\n",
    "    max_number = 0\n",
    "    max_level = 0\n",
    "    current_level = 0\n",
    "    keys = []\n",
    "   \n",
    "    #Helper function to test if value is transformable into float\n",
    "    def is_float(s):\n",
    "        try:\n",
    "            float(s)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "        \n",
    "    #Almsot same approach as in json, with recursive functions\n",
    "    def dic(d, level):\n",
    "        nonlocal max_number, max_level, current_level, keys\n",
    "        current_level = level\n",
    "        if current_level > max_level:\n",
    "            max_level = current_level\n",
    "\n",
    "        for k in d.keys():\n",
    "            keys.append(k)\n",
    "            if isinstance(d[k], dict):\n",
    "                dic(d[k], level + 1)\n",
    "            elif isinstance(d[k], list):\n",
    "                lista(d[k],level)\n",
    "            elif isinstance(d[k], str): \n",
    "                #Check if value is a number and transform it \n",
    "                t = 0\n",
    "                if d[k].isdigit(): t = int(d[k])\n",
    "                elif is_float(d[k]): t = float(d[k])\n",
    "                \n",
    "                if t > max_number:\n",
    "                    max_number = t\n",
    "                #First approach: robably usless every value is a string but it doesn't hurt\n",
    "            elif isinstance(d[k], (int,float)):\n",
    "                if d[k] > max_number:\n",
    "                    max_number = d[k]\n",
    "\n",
    "    def lista(x, level):\n",
    "        nonlocal max_number, max_level, current_level\n",
    "\n",
    "        for el in x:\n",
    "            if isinstance(el, list):\n",
    "                lista(el,level)\n",
    "            elif isinstance(el, dict):\n",
    "                dic(el, level + 1)\n",
    "            elif isinstance(el, str):\n",
    "                #Same as in dic\n",
    "                t = 0\n",
    "                if el.isdigit(): t = int(el)\n",
    "                elif is_float(el):d[k]: t = float(el)\n",
    "                \n",
    "                if t > max_number:\n",
    "                    max_number = t\n",
    "                            \n",
    "            elif isinstance(el, ( int, float)):              \n",
    "                if el > max_number:\n",
    "                    max_number = el\n",
    "    \n",
    "    #Evaluate the function\n",
    "    dic(data_dict,1)\n",
    "    \n",
    "    #Number of different keys\n",
    "    n_att = len(list(set(keys)))\n",
    "\n",
    "    diz[\"numberOfElementsAttributes\"] = n_att\n",
    "    diz[\"nestingDepth\"] = max_level\n",
    "    diz[\"maxNumericValue\"] = max_number\n",
    "\n",
    "    return diz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53e58d31-e57e-4ac6-84d3-48809e6b0d04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fc953a755d35d8c3255d3772e083002",
     "grade": true,
     "grade_id": "cell-eba7f348525a45dd",
     "locked": true,
     "points": 0.1875,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal, assert_in, assert_true\n",
    "assert_equal(len(describeFile(dataset1)), 3)\n",
    "assert_equal(len(describeFile(dataset2)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27d737cb-7aa3-4748-93f0-13f0c08d342b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2637ef320c218287599c8a8bc6cb63b",
     "grade": true,
     "grade_id": "cell-557eee89020c4510",
     "locked": true,
     "points": 0.1875,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb7ad07b-dc5c-4434-b06d-075591fe46f7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69a118b251422690870222cf5f042bb9",
     "grade": true,
     "grade_id": "cell-b125d2724a7003c1",
     "locked": true,
     "points": 0.1875,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1dbd6cf-d518-4b65-83b1-f36203b9e13c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0633205721d85edf11023800bffeaac2",
     "grade": true,
     "grade_id": "cell-c366624cc0d29728",
     "locked": true,
     "points": 0.1875,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e49feaf-64c0-4cd8-a9a8-98b29daf66e0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e58bb482889a5b09576fee3a30e6a295",
     "grade": true,
     "grade_id": "cell-2644ceec88376e7e",
     "locked": true,
     "points": 0.1875,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "017ede3e-7e5e-4f38-b9ca-c7254e5aa881",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2c8ba0c7a08c002c55f1fa22670ce27",
     "grade": true,
     "grade_id": "cell-75825a6fa21b6764",
     "locked": true,
     "points": 0.1875,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78c25532-33c7-4ea6-bbcb-1f23e0df07ad",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "309f12a43f4b8dcfeb3d324bbb15386e",
     "grade": true,
     "grade_id": "cell-1c787c4413548bab",
     "locked": true,
     "points": 0.1875,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dff5f404-fac2-46de-a8f1-444c906bb443",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "154b2599ee47b9c72a65428699e22484",
     "grade": true,
     "grade_id": "cell-2e575d64dfdbaa9b",
     "locked": true,
     "points": 0.1875,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70e38881-63b9-4f02-b301-30f7b96476d9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01c740615f5f15f8aa8493a689ec475f",
     "grade": true,
     "grade_id": "cell-4218dd06c8ea8833",
     "locked": true,
     "points": 0.1875,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "649287cc-d9d3-422b-8a47-25295ad8440a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9ecd21614153a677cbea1387012cb86",
     "grade": true,
     "grade_id": "cell-91e3b4cbf0931744",
     "locked": true,
     "points": 0.1875,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e44dac52-f1fe-4f5f-8d99-b27462a52af2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98cefcea6e84a1f4020f6d6c8edb0fd9",
     "grade": true,
     "grade_id": "cell-6fb522b91576b08f",
     "locked": true,
     "points": 0.1875,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5dec0094-1b71-4931-ba84-a3f8a6ee8230",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ffb610f2bde1f7c2eaceb6efb8268fe",
     "grade": true,
     "grade_id": "cell-5bab3319a1f792f9",
     "locked": true,
     "points": 0.1875,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7db940ce-f01a-4546-9e64-ce97ff0880fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4e54339e82a940891d1ecd304105500",
     "grade": true,
     "grade_id": "cell-2213630186aef937",
     "locked": true,
     "points": 0.1875,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fd6b71a-fd95-44f9-ad81-4ede19519cde",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc27fdeb6d52906b0f90f2e16d106c07",
     "grade": true,
     "grade_id": "cell-136ca0d44e2fd03d",
     "locked": true,
     "points": 0.1875,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c433c150-9c7c-4fd6-a162-4112d9d219b8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c03b7b23ac2048f0f560fa2d28f5d97",
     "grade": true,
     "grade_id": "cell-024d562b2d63af48",
     "locked": true,
     "points": 0.1875,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c4e48b9-fc7f-4e36-b450-f64c767513f8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2ed892a49dd9f7d2a0aa4d2d1fce759",
     "grade": true,
     "grade_id": "cell-469f1889794c4746",
     "locked": true,
     "points": 0.1875,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### DO NOT DELETE OR CHANGE THIS CELL!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385e1e37-e968-436f-ac91-a22154e6f32b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c2f16e71ca35453c63daed0b1106c6e",
     "grade": false,
     "grade_id": "cell-66aada55df321ea7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "***Final check:***\n",
    "\n",
    "Be sure to cross-check the results by\n",
    "1) manually inspecting your chosen dataset and\n",
    "2) comparing the results for plausibility against the results of your code... \n",
    "\n",
    "Describe your findings and use the following structure for your answer below:\n",
    "\n",
    "*Data set 1*\n",
    "\n",
    "(number and types of items etc., describe your findings)\n",
    "\n",
    "*Data set 2*\n",
    "\n",
    "(number and types of items etc., describe your findings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3bce1c-e495-4733-baa8-ddc2962f077f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df18cdf1882599d295da8465485a5b1c",
     "grade": true,
     "grade_id": "cell-4709b3248c430b6a",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Data set 1\n",
    "\n",
    "The first data set is probably a bit more difficult to inspect. \n",
    "\n",
    "The nesting depth and the number of elements seem coherent with the file.\n",
    "\n",
    "Regarding the biggest number to find in the data set, once we parsed the data set we are just presented with strings. However, knowing the nature of the data set and probably the scope of the task we decided to check for each entry if it is a float or an integer and then transformed it into a float or integer type. This of course implies some assumptions on the nature of the data, but we believe that our decision was in line with the context of the exercise. \n",
    "\n",
    "The biggest numerical value corresponds to an id. \n",
    "\n",
    "\n",
    "Data set 2\n",
    "\n",
    "The second data set (CSV) was probably easier to manually check. We opened the file in Excel and we found out that the dimensions of the file are the same as the one predicted by our function: 2769 rows and 7 columns.\n",
    "\n",
    "Also, in this case we had a similar situation as for data set 1, all entries are considered like strings. Inspecting the data set and also knowing the content it’s obvious that we should be presented with date columns and all the others with numerical values. However, basing our decision-making on the task description as well as on feedback from one of the tutorial sessions we left all values considered as string and we looked for the index of the column with the longest one.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
